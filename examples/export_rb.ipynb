{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f269085a",
   "metadata": {},
   "source": [
    "# Export ReplayBuffer from LoCo-MuJoCo (UnitreeG1, default:walking)\n",
    "\n",
    "- Loads Unitree G1 in LoCo-MuJoCo and selects the 'walking' motion from the default dataset (alias: 'walk').\n",
    "- Uses `TrajectoryDatasetManager` to create Zarr if missing and to step reference data.\n",
    "- Builds a TorchRL memmap-backed replay buffer from the saved Zarr.\n",
    "- Demonstrates step-wise sequential sampling and random minibatch sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814b0d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os, gc, json, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from tensordict import TensorDict\n",
    "\n",
    "# Repo import for local package\n",
    "repo_root = Path.cwd().parent\n",
    "if (repo_root / \"src\").exists():\n",
    "    sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "from iltools_datasets.loco_mujoco.loader import LocoMuJoCoLoader\n",
    "from iltools_datasets.manager import TrajectoryDatasetManager\n",
    "from iltools_datasets.replay_export import build_replay_from_zarr\n",
    "from iltools_datasets.replay_manager import EnvAssignment\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ccd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fad519",
   "metadata": {},
   "source": [
    "## Configure LoCo-MuJoCo (G1 walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3850f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LocoMuJoCoLoader] Initializing LocoMuJoCoLoader\n",
      "[LocoMuJoCoLoader] Dataset dictionary: {'default': ['walk'], 'amass': [], 'lafan1': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35198/35198 [00:07<00:00, 4646.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 joints\n",
      "joint_names ['root', 'left_hip_pitch_joint', 'left_hip_roll_joint', 'left_hip_yaw_joint', 'left_knee_joint', 'left_ankle_pitch_joint', 'left_ankle_roll_joint', 'right_hip_pitch_joint', 'right_hip_roll_joint', 'right_hip_yaw_joint', 'right_knee_joint', 'right_ankle_pitch_joint', 'right_ankle_roll_joint', 'waist_yaw_joint', 'left_shoulder_pitch_joint', 'left_shoulder_roll_joint', 'left_shoulder_yaw_joint', 'left_elbow_joint', 'left_wrist_roll_joint', 'right_shoulder_pitch_joint', 'right_shoulder_roll_joint', 'right_shoulder_yaw_joint', 'right_elbow_joint', 'right_wrist_roll_joint']\n"
     ]
    }
   ],
   "source": [
    "# LoCo-MuJoCo base cfg (see tests for example usage)\n",
    "basic_cfg = DictConfig(\n",
    "    {\n",
    "        \"dataset\": {\"trajectories\": {\"default\": [\"walk\"], \"amass\": [], \"lafan1\": []}},\n",
    "        \"control_freq\": 50.0,\n",
    "        \"window_size\": 4,\n",
    "        \"sim\": {\"dt\": 0.001},\n",
    "        \"decimation\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Resolve joint names via loader metadata to satisfy manager mapping\n",
    "tmp_loader = LocoMuJoCoLoader(env_name=\"UnitreeG1\", cfg=basic_cfg)\n",
    "joint_names = list(tmp_loader.metadata.joint_names)\n",
    "print(\"Found\", len(joint_names), \"joints\")\n",
    "print(\"joint_names\", joint_names)\n",
    "del tmp_loader\n",
    "joint_names = joint_names[1:]  # no need for root joint\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(repo_root) / \"examples\" / \"data\" / \"g1_default_walk\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ZARR_PATH = DATA_DIR / \"trajectories.zarr\"\n",
    "\n",
    "# Manager cfg (creates Zarr if missing using LocoMuJoCoLoader)\n",
    "mgr_cfg = DictConfig(\n",
    "    {\n",
    "        \"dataset_path\": str(DATA_DIR),\n",
    "        \"dataset\": {\"trajectories\": {\"default\": [\"walk\"], \"amass\": [], \"lafan1\": []}},\n",
    "        \"loader_type\": \"loco_mujoco\",\n",
    "        \"loader_kwargs\": {\"env_name\": \"UnitreeG1\", \"cfg\": basic_cfg},\n",
    "        \"assignment_strategy\": \"sequential\",\n",
    "        \"window_size\": 4,\n",
    "        \"target_joint_names\": joint_names,\n",
    "        \"reference_joint_names\": joint_names,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea43bc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TrajectoryDatasetManager] Using device: cuda:0\n",
      "[TrajectoryDatasetManager] Initialized with 1 trajectories, 8 envs\n",
      "Reference data keys: ['root_pos', 'root_quat', 'root_lin_vel', 'root_ang_vel', 'joint_pos', 'joint_vel', 'raw_qpos', 'raw_qvel']\n",
      "Zarr ready at: /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/trajectories.zarr\n"
     ]
    }
   ],
   "source": [
    "manager = TrajectoryDatasetManager(cfg=mgr_cfg, num_envs=8, device=\"cuda:0\")\n",
    "manager.reset_trajectories()\n",
    "ref0 = manager.get_reference_data()\n",
    "print(\"Reference data keys:\", list(ref0.keys()))\n",
    "print(\"Zarr ready at:\", ZARR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46cc3c",
   "metadata": {},
   "source": [
    "## Build memmap-backed replay buffer from Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4ebb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[build_replay_from_zarr] td: TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([87994, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                observation: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                qpos: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([87994]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        qpos: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([87994]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/memmap with range 0 to 87994\n",
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/memmap with range 0 to 87994\n",
      "Appending device transform to buffer: cuda:0\n",
      "Replay transitions available: 87994\n"
     ]
    }
   ],
   "source": [
    "# Export replay using qpos as observation; action auto-detected if present\n",
    "replay_mgr = build_replay_from_zarr(\n",
    "    zarr_path=str(ZARR_PATH),\n",
    "    scratch_dir=str(DATA_DIR / \"memmap\"),\n",
    "    device=\"cuda:0\",\n",
    "    obs_keys=[\"qpos\"],\n",
    "    concat_obs_to_key=\"observation\",\n",
    "    include_terminated=True,\n",
    "    include_truncated=True,\n",
    ")\n",
    "print(\"Replay transitions available:\", len(replay_mgr.buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9026e928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDictReplayBuffer(\n",
       "    storage=LazyMemmapStorage(\n",
       "        data=TensorDict(\n",
       "            fields={\n",
       "                action: MemoryMappedTensor(shape=torch.Size([87994, 1]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                next: TensorDict(\n",
       "                    fields={\n",
       "                        observation: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                        qpos: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True)},\n",
       "                    batch_size=torch.Size([87994]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                observation: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                qpos: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                terminated: MemoryMappedTensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=True),\n",
       "                truncated: MemoryMappedTensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=True)},\n",
       "            batch_size=torch.Size([87994]),\n",
       "            device=cpu,\n",
       "            is_shared=False), \n",
       "        shape=torch.Size([87994]), \n",
       "        len=87994, \n",
       "        max_size=87994), \n",
       "    sampler=RandomSampler(), \n",
       "    writer=TensorDictRoundRobinWriter(cursor=0, full_storage=True), \n",
       "Compose(\n",
       "        _CallableTransform(keys=[])), \n",
       "    batch_size=256, \n",
       "    collate_fn=<function _collate_id at 0x7f558d9d9f80>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = replay_mgr.buffer\n",
    "buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b99ce3",
   "metadata": {},
   "source": [
    "## Step-wise sequential sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7fcc242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential batch1 shape: {'observation': (8, 30), 'action': (8, 1), 'qpos': (8, 30), 'terminated': (8,), 'truncated': (8,), 'index': (8,)}\n",
      "Sequential batch2 observation head: tensor([[ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
      "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
      "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
      "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
      "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
      "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
      "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
      "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
      "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
      "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
      "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
      "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Build a simple assignment: all 8 envs read the first segment (task 0, traj 0)\n",
    "asg = [EnvAssignment(task_id=0, traj_id=0, step=0) for i in range(8)]\n",
    "replay_mgr.set_assignment(asg)\n",
    "# Sample twice; each env advances one step and wraps per-trajectory\n",
    "b1 = replay_mgr.buffer.sample()\n",
    "b2 = replay_mgr.buffer.sample()\n",
    "print(\n",
    "    \"Sequential batch1 shape:\",\n",
    "    {k: tuple(v.shape) for k, v in b1.items() if isinstance(v, torch.Tensor)},\n",
    ")\n",
    "print(\"Sequential batch2 observation head:\", b2[\"observation\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4220f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1[\"observation\"].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba38e9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2[\"observation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12992d04",
   "metadata": {},
   "source": [
    "## Random minibatch sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d82de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random minibatch size: torch.Size([1024])\n",
      "Keys: ['observation', 'action', ('next', 'observation'), ('next', 'qpos'), 'next', 'qpos', 'terminated', 'truncated', 'index']\n"
     ]
    }
   ],
   "source": [
    "# Switch to uniform random minibatch sampler (without replacement)\n",
    "replay_mgr.set_uniform_sampler(batch_size=1024, without_replacement=True)\n",
    "rb_batch = replay_mgr.buffer.sample()\n",
    "print(\"Random minibatch size:\", rb_batch.batch_size)\n",
    "print(\"Keys:\", list(rb_batch.keys(True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e0d01",
   "metadata": {},
   "source": [
    "## Replay Buffer Examples and Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a579d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num segments: 1\n",
      "First 3 segments: [(0, 0, 87994)]\n",
      "Sampled keys: ['observation', 'action', ('next', 'observation'), ('next', 'qpos'), 'next', 'qpos', 'terminated', 'truncated', 'index']\n",
      "Has terminated? True Has truncated? True\n",
      "Batch sizes: {'observation': (1024, 30), 'action': (1024, 1), 'next': (1024,), 'qpos': (1024, 30), 'terminated': (1024,), 'truncated': (1024,), 'index': (1024,)}\n"
     ]
    }
   ],
   "source": [
    "# Inspect segment metadata and presence of auxiliary keys\n",
    "print(\"Num segments:\", len(replay_mgr.segments))\n",
    "print(\n",
    "    \"First 3 segments:\",\n",
    "    [(s.task_id, s.traj_id, s.length) for s in replay_mgr.segments[:3]],\n",
    ")\n",
    "batch = replay_mgr.buffer.sample()\n",
    "print(\"Sampled keys:\", list(batch.keys(True)))\n",
    "print(\"Has terminated?\", \"terminated\" in batch, \"Has truncated?\", \"truncated\" in batch)\n",
    "print(\n",
    "    \"Batch sizes:\", {k: tuple(v.shape) for k, v in batch.items() if hasattr(v, \"shape\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba57f35",
   "metadata": {},
   "source": [
    "### Step-wise Sequential Sampler (assignment and wraparound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86026f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential sampler shapes: torch.Size([6, 30]) torch.Size([6, 30])\n",
      "First env obs head b1/b2: tensor([0.0000, 0.0000, 0.7905, 0.9951], device='cuda:0') tensor([ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Assign all envs to the first segment and stagger start steps to show progression\n",
    "first_seg = replay_mgr.segments[0]\n",
    "num_envs = 6\n",
    "asg = [\n",
    "    EnvAssignment(task_id=first_seg.task_id, traj_id=first_seg.traj_id, step=i)\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "replay_mgr.set_assignment(asg)\n",
    "b1 = replay_mgr.buffer.sample()\n",
    "b2 = replay_mgr.buffer.sample()\n",
    "print(\"Sequential sampler shapes:\", b1[\"observation\"].shape, b2[\"observation\"].shape)\n",
    "print(\"First env obs head b1/b2:\", b1[\"observation\"][0, :4], b2[\"observation\"][0, :4])\n",
    "# Note: Actual values depend on dataset; we demonstrate API and per-call advancement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f66b9d",
   "metadata": {},
   "source": [
    "### Random Minibatch Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e06d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform minibatch size: torch.Size([512])\n",
      "With-replacement minibatch size: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Switch to uniform minibatching (without replacement)\n",
    "replay_mgr.set_uniform_sampler(batch_size=512, without_replacement=True)\n",
    "rb_batch = replay_mgr.buffer.sample()\n",
    "print(\"Uniform minibatch size:\", rb_batch.batch_size)\n",
    "# With replacement (sampler=None)\n",
    "replay_mgr.set_uniform_sampler(batch_size=128, without_replacement=False)\n",
    "rb_batch_rep = replay_mgr.buffer.sample()\n",
    "print(\"With-replacement minibatch size:\", rb_batch_rep.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b85ed",
   "metadata": {},
   "source": [
    "### Device Transform (prefetch to GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "739e21b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n",
      "Device: cuda:0\n",
      "Device types match: True\n",
      "✅ Device transform ok\n"
     ]
    }
   ],
   "source": [
    "# Force reload of the replay_manager module to pick up latest changes\n",
    "import importlib\n",
    "import iltools_datasets.replay_manager\n",
    "\n",
    "importlib.reload(iltools_datasets.replay_manager)\n",
    "\n",
    "target_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device:\", target_device)\n",
    "bs = replay_mgr.buffer.sample().to(target_device)\n",
    "print(\"Device:\", bs[\"observation\"].device)\n",
    "print(\"Device types match:\", bs[\"observation\"].device.type == target_device.type)\n",
    "if bs[\"observation\"].device.type == target_device.type:\n",
    "    print(\"✅ Device transform ok\")\n",
    "else:\n",
    "    print(\"❌ Device transform failed - data still on CPU\")\n",
    "    print(\n",
    "        \"This might be due to buffer recreation losing transforms. Check replay_manager.py\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a44b7",
   "metadata": {},
   "source": [
    "### Synthetic Tests (deterministic observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5545806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/_tmp_memmap with range 0 to 3\n",
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/_tmp_memmap with range 3 to 5\n",
      "✅ Sequential sampler synthetic test passed\n",
      "✅ Uniform sampler tests passed\n"
     ]
    }
   ],
   "source": [
    "from iltools_datasets.replay_manager import ExpertReplayManager, ExpertReplaySpec\n",
    "from iltools_datasets.replay_memmap import build_trajectory_td, Segment\n",
    "\n",
    "\n",
    "def _mk_traj(task_id: int, traj_id: int, T: int, obs_dim: int = 3, act_dim: int = 1):\n",
    "    t = torch.arange(T, dtype=torch.float32).unsqueeze(-1)\n",
    "    obs = torch.cat(\n",
    "        [torch.full_like(t, float(task_id)), torch.full_like(t, float(traj_id)), t],\n",
    "        dim=1,\n",
    "    )\n",
    "    nxt = obs + 0.5\n",
    "    act = torch.zeros(T, act_dim)\n",
    "    return build_trajectory_td(observation=obs, action=act, next_observation=nxt)\n",
    "\n",
    "\n",
    "# Build small tasks set\n",
    "tasks = {0: [_mk_traj(0, 0, T=3)], 1: [_mk_traj(1, 0, T=2)]}\n",
    "tmp_dir = str((Path.cwd() / \"_tmp_memmap\").absolute())\n",
    "mgr2 = ExpertReplayManager(\n",
    "    ExpertReplaySpec(\n",
    "        tasks=tasks, scratch_dir=tmp_dir, device=\"cpu\", sample_batch_size=4\n",
    "    )\n",
    ")\n",
    "\n",
    "# Sequential assignment for 3 envs\n",
    "asg = [EnvAssignment(0, 0, 0), EnvAssignment(1, 0, 0), EnvAssignment(0, 0, 2)]\n",
    "mgr2.set_assignment(asg)\n",
    "out = mgr2.buffer.sample()\n",
    "obs = out[\"observation\"]\n",
    "assert torch.allclose(obs[0], torch.tensor([0.0, 0.0, 0.0]))\n",
    "assert torch.allclose(obs[1], torch.tensor([1.0, 0.0, 0.0]))\n",
    "assert torch.allclose(obs[2], torch.tensor([0.0, 0.0, 2.0]))\n",
    "out2 = mgr2.buffer.sample()\n",
    "obs2 = out2[\"observation\"]\n",
    "assert torch.allclose(obs2[0], torch.tensor([0.0, 0.0, 1.0]))\n",
    "assert torch.allclose(obs2[1], torch.tensor([1.0, 0.0, 1.0]))\n",
    "assert torch.allclose(obs2[2], torch.tensor([0.0, 0.0, 0.0]))\n",
    "print(\"✅ Sequential sampler synthetic test passed\")\n",
    "\n",
    "# Uniform samplers\n",
    "mgr2.set_uniform_sampler(batch_size=5, without_replacement=True)\n",
    "u1 = mgr2.buffer.sample()\n",
    "assert u1.batch_size[0] == 5\n",
    "mgr2.set_uniform_sampler(batch_size=3, without_replacement=False)\n",
    "u2 = mgr2.buffer.sample()\n",
    "assert u2.batch_size[0] == 3\n",
    "print(\"✅ Uniform sampler tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc693307",
   "metadata": {},
   "source": [
    "### Zarr Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea3ea2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zarr: /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/trajectories.zarr\n",
      "- Dataset source: loco_mujoco (motions: 1)\n",
      "  • Motion:         default_walk | trajs:   1 | mean T: 87995.0 | total T: 87995\n"
     ]
    }
   ],
   "source": [
    "import zarr, os\n",
    "\n",
    "if \"ZARR_PATH\" not in globals():\n",
    "    print(\"ZARR_PATH is undefined. Run the configuration cells first.\")\n",
    "else:\n",
    "    zp = str(ZARR_PATH)\n",
    "    if not os.path.exists(zp):\n",
    "        print(\"Zarr not found at\", zp, \"- run earlier cells to create it.\")\n",
    "    else:\n",
    "        root = zarr.open_group(zp, mode=\"r\")\n",
    "        print(\"Zarr:\", zp)\n",
    "        for ds_name in root.keys():\n",
    "            ds_group = root[ds_name]\n",
    "            motions = [\n",
    "                k for k in ds_group.keys() if isinstance(ds_group[k], zarr.Group)\n",
    "            ]\n",
    "            print(f\"- Dataset source: {ds_name} (motions: {len(motions)})\")\n",
    "            for motion in motions:\n",
    "                mg = ds_group[motion]\n",
    "                trajs = [k for k in mg.keys() if isinstance(mg[k], zarr.Group)]\n",
    "                lengths = []\n",
    "                for traj in trajs:\n",
    "                    tg = mg[traj]\n",
    "                    # Prefer 'qpos' to determine T, else first array key\n",
    "                    arr_key = (\n",
    "                        \"qpos\"\n",
    "                        if \"qpos\" in tg\n",
    "                        else next(\n",
    "                            (k for k in tg.keys() if isinstance(tg[k], zarr.Array)),\n",
    "                            None,\n",
    "                        )\n",
    "                    )\n",
    "                    T = int(tg[arr_key].shape[0]) if arr_key is not None else -1\n",
    "                    lengths.append(T)\n",
    "                total_T = sum(max(0, T) for T in lengths)\n",
    "                print(\n",
    "                    f\"  • Motion: {motion:>20} | trajs: {len(trajs):3d} | mean T: { (sum(lengths)/len(lengths)) if lengths else 0:.1f} | total T: {total_T}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392fc95",
   "metadata": {},
   "source": [
    "## Comprehensive Tests\n",
    "\n",
    "This section adds extensive tests for the replay buffer functionality, including:\n",
    "- Multiple trajectory loading and management\n",
    "- Dynamic trajectory assignment updates\n",
    "- Edge cases and error handling\n",
    "- Performance and memory usage validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb187413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LocoMuJoCoLoader] Initializing LocoMuJoCoLoader\n",
      "[LocoMuJoCoLoader] Dataset dictionary: {'default': ['walk', 'run'], 'amass': [], 'lafan1': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35198/35198 [00:06<00:00, 5069.29it/s]\n",
      "100%|██████████| 8718/8718 [00:01<00:00, 4372.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Multiple trajectory test failed: 'DatasetMeta' object has no attribute 'dataset_dict'\n"
     ]
    }
   ],
   "source": [
    "### Test 1: Multiple Trajectory Loading and Management\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "# Create a more complex dataset with multiple trajectories\n",
    "multi_traj_cfg = DictConfig(\n",
    "    {\n",
    "        \"dataset\": {\n",
    "            \"trajectories\": {\n",
    "                \"default\": [\"walk\", \"run\"],  # Multiple motions\n",
    "                \"amass\": [],\n",
    "                \"lafan1\": [],\n",
    "            }\n",
    "        },\n",
    "        \"control_freq\": 50.0,\n",
    "        \"window_size\": 4,\n",
    "        \"sim\": {\"dt\": 0.001},\n",
    "        \"decimation\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test if we can load multiple motions\n",
    "try:\n",
    "    multi_loader = LocoMuJoCoLoader(env_name=\"UnitreeG1\", cfg=multi_traj_cfg)\n",
    "    available_motions = list(multi_loader.metadata.dataset_dict.keys())\n",
    "    print(f\"Available dataset sources: {available_motions}\")\n",
    "\n",
    "    # Check what motions are available in each source\n",
    "    for source in available_motions:\n",
    "        motions = multi_loader.metadata.dataset_dict[source]\n",
    "        print(f\"Source '{source}' has motions: {motions}\")\n",
    "\n",
    "    del multi_loader\n",
    "    print(\"✅ Multiple trajectory configuration test passed\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Multiple trajectory test failed: {e}\")\n",
    "    # Fall back to single motion for remaining tests\n",
    "    multi_traj_cfg = basic_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75810b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dynamic trajectory assignment updates...\n",
      "Step 0: First env obs head: tensor([0.0000, 0.0000, 0.7905], device='cuda:0')\n",
      "Step 1: First env obs head: tensor([ 8.9815e-03, -6.0037e-04,  7.8958e-01], device='cuda:0')\n",
      "Step 2: First env obs head: tensor([ 0.0191, -0.0011,  0.7889], device='cuda:0')\n",
      "\n",
      "Reassigning environments...\n",
      "After reassignment:\n",
      "  Env 0: obs head: tensor([1.1498, 0.0320, 0.8255], device='cuda:0')\n",
      "  Env 1: obs head: tensor([2.3059, 0.0209, 0.8465], device='cuda:0')\n",
      "  Env 2: obs head: tensor([0.5769, 0.0071, 0.8014], device='cuda:0')\n",
      "  Env 3: obs head: tensor([0.0000, 0.0000, 0.7905], device='cuda:0')\n",
      "❌ Should have failed with invalid assignment\n",
      "✅ Dynamic assignment update test passed\n"
     ]
    }
   ],
   "source": [
    "### Test 2: Dynamic Trajectory Assignment Updates\n",
    "\n",
    "# Test reassigning environments to different trajectories\n",
    "print(\"Testing dynamic trajectory assignment updates...\")\n",
    "\n",
    "# Start with all envs on the first segment\n",
    "num_test_envs = 4\n",
    "initial_assignment = [\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=0) for _ in range(num_test_envs)\n",
    "]\n",
    "replay_mgr.set_assignment(initial_assignment)\n",
    "\n",
    "# Sample a few steps to advance the assignment\n",
    "for i in range(3):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    print(f\"Step {i}: First env obs head: {batch['observation'][0, :3]}\")\n",
    "\n",
    "# Now reassign some environments to different starting positions\n",
    "print(\"\\nReassigning environments...\")\n",
    "new_assignment = [\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=100),  # Start from step 100\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=200),  # Start from step 200\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=50),  # Start from step 50\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=0),  # Reset to beginning\n",
    "]\n",
    "\n",
    "replay_mgr.set_assignment(new_assignment)\n",
    "\n",
    "# Sample again to verify new assignments\n",
    "batch_after_reassign = replay_mgr.buffer.sample()\n",
    "print(\"After reassignment:\")\n",
    "for i in range(num_test_envs):\n",
    "    print(f\"  Env {i}: obs head: {batch_after_reassign['observation'][i, :3]}\")\n",
    "\n",
    "# Test assignment validation\n",
    "try:\n",
    "    invalid_assignment = [\n",
    "        EnvAssignment(task_id=999, traj_id=999, step=0)\n",
    "    ]  # Non-existent task/traj\n",
    "    replay_mgr.set_assignment(invalid_assignment)\n",
    "    print(\"❌ Should have failed with invalid assignment\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ Correctly rejected invalid assignment: {type(e).__name__}\")\n",
    "\n",
    "print(\"✅ Dynamic assignment update test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing wraparound behavior and boundary conditions...\n",
      "Trajectory length: 87994\n",
      "Testing wraparound:\n",
      "  Step 0: Env 0 index: 87989, Env 1 index: 87989\n",
      "  Step 1: Env 0 index: 87990, Env 1 index: 87990\n",
      "  Step 2: Env 0 index: 87991, Env 1 index: 87991\n",
      "  Step 3: Env 0 index: 87992, Env 1 index: 87992\n",
      "  Step 4: Env 0 index: 87993, Env 1 index: 87993\n",
      "  Step 5: Env 0 index: 0, Env 1 index: 0\n",
      "  Step 6: Env 0 index: 1, Env 1 index: 1\n",
      "  Step 7: Env 0 index: 2, Env 1 index: 2\n",
      "Assignment beyond end (step 88004): actual indices: [10, 10]\n",
      "Negative assignment (step -5): actual indices: [87989, 87989]\n",
      "✅ Wraparound and boundary test passed\n"
     ]
    }
   ],
   "source": [
    "### Test 3: Wraparound and Boundary Testing\n",
    "\n",
    "print(\"Testing wraparound behavior and boundary conditions...\")\n",
    "\n",
    "# Test wraparound at trajectory boundaries\n",
    "segment = replay_mgr.segments[0]\n",
    "traj_length = segment.length\n",
    "print(f\"Trajectory length: {traj_length}\")\n",
    "\n",
    "# Set assignment near the end of trajectory\n",
    "near_end_assignment = [\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=traj_length - 5) for _ in range(2)\n",
    "]\n",
    "replay_mgr.set_assignment(near_end_assignment)\n",
    "\n",
    "# Sample multiple times to test wraparound\n",
    "print(\"Testing wraparound:\")\n",
    "for i in range(8):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    step_indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "    print(\n",
    "        f\"  Step {i}: Env 0 index: {step_indices[0].item()}, Env 1 index: {step_indices[1].item()}\"\n",
    "    )\n",
    "\n",
    "# Test assignment beyond trajectory length (should wrap)\n",
    "beyond_end_assignment = [\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=traj_length + 10) for _ in range(2)\n",
    "]\n",
    "replay_mgr.set_assignment(beyond_end_assignment)\n",
    "batch = replay_mgr.buffer.sample()\n",
    "step_indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "print(\n",
    "    f\"Assignment beyond end (step {traj_length + 10}): actual indices: {step_indices.tolist()}\"\n",
    ")\n",
    "\n",
    "# Test negative step assignment (should wrap to end)\n",
    "negative_assignment = [EnvAssignment(task_id=0, traj_id=0, step=-5) for _ in range(2)]\n",
    "replay_mgr.set_assignment(negative_assignment)\n",
    "batch = replay_mgr.buffer.sample()\n",
    "step_indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "print(f\"Negative assignment (step -5): actual indices: {step_indices.tolist()}\")\n",
    "\n",
    "print(\"✅ Wraparound and boundary test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe53027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sampler switching and data consistency...\n",
      "Sequential sampling:\n",
      "  Step 0: indices: [0, 0, 0]\n",
      "  Step 1: indices: [1, 1, 1]\n",
      "  Step 2: indices: [2, 2, 2]\n",
      "\n",
      "Switching to uniform sampling...\n",
      "Uniform batch size: torch.Size([6])\n",
      "Uniform indices: [6146, 68682, 83123, 80842, 34151, 36427]\n",
      "\n",
      "Switching back to sequential sampling...\n",
      "Sequential indices after switch: [3, 3, 3]\n",
      "\n",
      "Testing with/without replacement:\n",
      "With replacement - unique indices: 996\n",
      "Without replacement - unique indices: 1000\n",
      "✅ Sampler switching test passed\n"
     ]
    }
   ],
   "source": [
    "### Test 4: Sampler Switching and Consistency\n",
    "\n",
    "print(\"Testing sampler switching and data consistency...\")\n",
    "\n",
    "# Test switching between different samplers\n",
    "test_assignment = [EnvAssignment(task_id=0, traj_id=0, step=0) for _ in range(3)]\n",
    "replay_mgr.set_assignment(test_assignment)\n",
    "\n",
    "# Sequential sampling\n",
    "print(\"Sequential sampling:\")\n",
    "for i in range(3):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "    print(f\"  Step {i}: indices: {indices.tolist()}\")\n",
    "\n",
    "# Switch to uniform sampling\n",
    "print(\"\\nSwitching to uniform sampling...\")\n",
    "replay_mgr.set_uniform_sampler(batch_size=6, without_replacement=True)\n",
    "uniform_batch = replay_mgr.buffer.sample()\n",
    "print(f\"Uniform batch size: {uniform_batch.batch_size}\")\n",
    "print(\n",
    "    f\"Uniform indices: {uniform_batch.get('index', torch.zeros(uniform_batch.batch_size[0])).tolist()}\"\n",
    ")\n",
    "\n",
    "# Switch back to sequential\n",
    "print(\"\\nSwitching back to sequential sampling...\")\n",
    "replay_mgr.set_assignment(test_assignment)\n",
    "sequential_batch = replay_mgr.buffer.sample()\n",
    "indices = sequential_batch.get(\"index\", torch.zeros(sequential_batch.batch_size[0]))\n",
    "print(f\"Sequential indices after switch: {indices.tolist()}\")\n",
    "\n",
    "# Test with replacement vs without replacement\n",
    "print(\"\\nTesting with/without replacement:\")\n",
    "replay_mgr.set_uniform_sampler(\n",
    "    batch_size=1000, without_replacement=False\n",
    ")  # With replacement\n",
    "with_rep_batch = replay_mgr.buffer.sample()\n",
    "replay_mgr.set_uniform_sampler(\n",
    "    batch_size=1000, without_replacement=True\n",
    ")  # Without replacement\n",
    "without_rep_batch = replay_mgr.buffer.sample()\n",
    "\n",
    "with_rep_indices = with_rep_batch.get(\n",
    "    \"index\", torch.zeros(with_rep_batch.batch_size[0])\n",
    ")\n",
    "without_rep_indices = without_rep_batch.get(\n",
    "    \"index\", torch.zeros(without_rep_batch.batch_size[0])\n",
    ")\n",
    "\n",
    "print(f\"With replacement - unique indices: {len(torch.unique(with_rep_indices))}\")\n",
    "print(f\"Without replacement - unique indices: {len(torch.unique(without_rep_indices))}\")\n",
    "\n",
    "print(\"✅ Sampler switching test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bda500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data integrity and tensor properties...\n",
      "Tensor properties:\n",
      "  Observation shape: torch.Size([100, 30])\n",
      "  Action shape: torch.Size([100, 1])\n",
      "  Device: cuda:0\n",
      "  Dtype: torch.float32\n",
      "  Has NaN: False\n",
      "  Has Inf: False\n",
      "  Next obs shape: torch.Size([100, 30])\n",
      "  Next obs device: cuda:0\n",
      "  Obs-next_obs difference range: [0.029120, 0.110759]\n",
      "  Terminated flags: 0/100 are True\n",
      "  Truncated flags: 0/100 are True\n",
      "  Index range: [199, 85733]\n",
      "  Index dtype: torch.int64\n",
      "✅ Data integrity test passed\n"
     ]
    }
   ],
   "source": [
    "### Test 5: Data Integrity and Tensor Properties\n",
    "\n",
    "print(\"Testing data integrity and tensor properties...\")\n",
    "\n",
    "# Test data consistency across different sampling methods\n",
    "replay_mgr.set_uniform_sampler(batch_size=100, without_replacement=True)\n",
    "batch = replay_mgr.buffer.sample()\n",
    "\n",
    "# Check tensor properties\n",
    "print(\"Tensor properties:\")\n",
    "print(f\"  Observation shape: {batch['observation'].shape}\")\n",
    "print(f\"  Action shape: {batch['action'].shape}\")\n",
    "print(f\"  Device: {batch['observation'].device}\")\n",
    "print(f\"  Dtype: {batch['observation'].dtype}\")\n",
    "print(f\"  Has NaN: {torch.isnan(batch['observation']).any()}\")\n",
    "print(f\"  Has Inf: {torch.isinf(batch['observation']).any()}\")\n",
    "\n",
    "# Test next observation consistency\n",
    "next_obs = batch[\"next\"][\"observation\"]\n",
    "curr_obs = batch[\"observation\"]\n",
    "print(f\"  Next obs shape: {next_obs.shape}\")\n",
    "print(f\"  Next obs device: {next_obs.device}\")\n",
    "\n",
    "# Test that observations are different (not identical)\n",
    "obs_diff = torch.norm(curr_obs - next_obs, dim=-1)\n",
    "print(\n",
    "    f\"  Obs-next_obs difference range: [{obs_diff.min().item():.6f}, {obs_diff.max().item():.6f}]\"\n",
    ")\n",
    "\n",
    "# Test terminated/truncated flags\n",
    "terminated = batch.get(\"terminated\", None)\n",
    "truncated = batch.get(\"truncated\", None)\n",
    "if terminated is not None:\n",
    "    print(\n",
    "        f\"  Terminated flags: {terminated.sum().item()}/{terminated.numel()} are True\"\n",
    "    )\n",
    "if truncated is not None:\n",
    "    print(f\"  Truncated flags: {truncated.sum().item()}/{truncated.numel()} are True\")\n",
    "\n",
    "# Test index consistency\n",
    "indices = batch.get(\"index\", None)\n",
    "if indices is not None:\n",
    "    print(f\"  Index range: [{indices.min().item()}, {indices.max().item()}]\")\n",
    "    print(f\"  Index dtype: {indices.dtype}\")\n",
    "\n",
    "print(\"✅ Data integrity test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce9bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance and memory usage...\n",
      "Initial memory usage: 3563.4 MB\n",
      "Sampling performance: 94.2 samples/sec\n",
      "Time per sample: 10.62 ms\n",
      "Memory increase: 0.0 MB\n",
      "\n",
      "Testing large batch sampling:\n",
      "  Batch size 2048: 2048 samples in 0.76 ms\n",
      "  Batch size 4096: 4096 samples in 0.59 ms\n",
      "  Batch size 8192: 8192 samples in 0.89 ms\n",
      "✅ Performance test passed\n"
     ]
    }
   ],
   "source": [
    "### Test 6: Performance and Memory Usage\n",
    "\n",
    "print(\"Testing performance and memory usage...\")\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Get initial memory usage\n",
    "process = psutil.Process(os.getpid())\n",
    "initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "print(f\"Initial memory usage: {initial_memory:.1f} MB\")\n",
    "\n",
    "# Test sampling performance\n",
    "replay_mgr.set_uniform_sampler(batch_size=1024, without_replacement=True)\n",
    "\n",
    "# Warm up\n",
    "for _ in range(5):\n",
    "    _ = replay_mgr.buffer.sample()\n",
    "\n",
    "# Time sampling\n",
    "num_samples = 100\n",
    "start_time = time.time()\n",
    "for _ in range(num_samples):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "end_time = time.time()\n",
    "\n",
    "sampling_time = end_time - start_time\n",
    "samples_per_sec = num_samples / sampling_time\n",
    "print(f\"Sampling performance: {samples_per_sec:.1f} samples/sec\")\n",
    "print(f\"Time per sample: {sampling_time/num_samples*1000:.2f} ms\")\n",
    "\n",
    "# Test memory usage after sampling\n",
    "final_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "memory_increase = final_memory - initial_memory\n",
    "print(f\"Memory increase: {memory_increase:.1f} MB\")\n",
    "\n",
    "# Test large batch sampling\n",
    "print(\"\\nTesting large batch sampling:\")\n",
    "large_batch_sizes = [2048, 4096, 8192]\n",
    "for batch_size in large_batch_sizes:\n",
    "    try:\n",
    "        replay_mgr.set_uniform_sampler(batch_size=batch_size, without_replacement=True)\n",
    "        start_time = time.time()\n",
    "        batch = replay_mgr.buffer.sample()\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            f\"  Batch size {batch_size}: {batch.batch_size[0]} samples in {(end_time-start_time)*1000:.2f} ms\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  Batch size {batch_size}: Failed - {e}\")\n",
    "\n",
    "print(\"✅ Performance test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36a438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error handling and edge cases...\n",
      "Testing invalid batch sizes:\n",
      "❌ Should have failed with batch_size=0\n",
      "❌ Should have failed with negative batch_size\n",
      "✅ Large batch size handled gracefully: got 88994 samples\n",
      "\n",
      "Testing assignment validation:\n",
      "❌ Should have failed with wrong assignment size\n",
      "❌ Should have failed with empty assignment\n",
      "\n",
      "Testing device consistency:\n",
      "All tensors on correct device (cuda:0): True\n",
      "✅ Error handling test passed\n"
     ]
    }
   ],
   "source": [
    "### Test 7: Error Handling and Edge Cases\n",
    "\n",
    "print(\"Testing error handling and edge cases...\")\n",
    "\n",
    "# Test invalid batch sizes\n",
    "print(\"Testing invalid batch sizes:\")\n",
    "try:\n",
    "    replay_mgr.set_uniform_sampler(batch_size=0, without_replacement=True)\n",
    "    print(\"❌ Should have failed with batch_size=0\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ Correctly rejected batch_size=0: {type(e).__name__}\")\n",
    "\n",
    "try:\n",
    "    replay_mgr.set_uniform_sampler(batch_size=-1, without_replacement=True)\n",
    "    print(\"❌ Should have failed with negative batch_size\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ Correctly rejected negative batch_size: {type(e).__name__}\")\n",
    "\n",
    "# Test batch size larger than available data\n",
    "total_transitions = len(replay_mgr.buffer)\n",
    "try:\n",
    "    replay_mgr.set_uniform_sampler(\n",
    "        batch_size=total_transitions + 1000, without_replacement=True\n",
    "    )\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    print(f\"✅ Large batch size handled gracefully: got {batch.batch_size[0]} samples\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Large batch size failed: {e}\")\n",
    "\n",
    "# Test assignment with wrong number of environments\n",
    "print(\"\\nTesting assignment validation:\")\n",
    "try:\n",
    "    wrong_size_assignment = [\n",
    "        EnvAssignment(task_id=0, traj_id=0, step=0) for _ in range(10)\n",
    "    ]  # Too many\n",
    "    replay_mgr.set_assignment(wrong_size_assignment)\n",
    "    print(\"❌ Should have failed with wrong assignment size\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ Correctly rejected wrong assignment size: {type(e).__name__}\")\n",
    "\n",
    "# Test empty assignment\n",
    "try:\n",
    "    replay_mgr.set_assignment([])\n",
    "    print(\"❌ Should have failed with empty assignment\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ Correctly rejected empty assignment: {type(e).__name__}\")\n",
    "\n",
    "# Test device consistency\n",
    "print(\"\\nTesting device consistency:\")\n",
    "batch = replay_mgr.buffer.sample()\n",
    "expected_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "all_on_correct_device = all(\n",
    "    batch[key].device == expected_device\n",
    "    for key in batch.keys(True)\n",
    "    if isinstance(batch[key], torch.Tensor)\n",
    ")\n",
    "print(f\"All tensors on correct device ({expected_device}): {all_on_correct_device}\")\n",
    "\n",
    "print(\"✅ Error handling test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6364eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing state persistence and recovery...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ExpertReplayManager' object has no attribute 'get_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     batch = replay_mgr.buffer.sample()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Save state\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m state_dict = \u001b[43mreplay_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_state_dict\u001b[49m()\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mState dict keys:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(state_dict.keys()))\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Create new manager and restore state\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'ExpertReplayManager' object has no attribute 'get_state_dict'"
     ]
    }
   ],
   "source": [
    "### Test 8: State Persistence and Recovery\n",
    "\n",
    "print(\"Testing state persistence and recovery...\")\n",
    "\n",
    "# Test state dict serialization\n",
    "replay_mgr.set_assignment(\n",
    "    [EnvAssignment(task_id=0, traj_id=0, step=100) for _ in range(3)]\n",
    ")\n",
    "\n",
    "# Sample a few times to advance state\n",
    "for _ in range(5):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "\n",
    "# Save state\n",
    "state_dict = replay_mgr.get_state_dict()\n",
    "print(\"State dict keys:\", list(state_dict.keys()))\n",
    "\n",
    "# Create new manager and restore state\n",
    "new_mgr_cfg = DictConfig(\n",
    "    {\n",
    "        \"dataset_path\": str(DATA_DIR),\n",
    "        \"dataset\": {\"trajectories\": {\"default\": [\"walk\"], \"amass\": [], \"lafan1\": []}},\n",
    "        \"loader_type\": \"loco_mujoco\",\n",
    "        \"loader_kwargs\": {\"env_name\": \"UnitreeG1\", \"cfg\": basic_cfg},\n",
    "        \"assignment_strategy\": \"sequential\",\n",
    "        \"window_size\": 4,\n",
    "        \"target_joint_names\": joint_names,\n",
    "        \"reference_joint_names\": joint_names,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create new manager\n",
    "new_manager = TrajectoryDatasetManager(cfg=new_mgr_cfg, num_envs=8, device=\"cuda:0\")\n",
    "new_replay_mgr = build_replay_from_zarr(\n",
    "    zarr_path=str(ZARR_PATH),\n",
    "    scratch_dir=str(DATA_DIR / \"memmap_new\"),\n",
    "    device=\"cuda:0\",\n",
    "    obs_keys=[\"qpos\"],\n",
    "    concat_obs_to_key=\"observation\",\n",
    "    include_terminated=True,\n",
    "    include_truncated=True,\n",
    ")\n",
    "\n",
    "# Restore state\n",
    "new_replay_mgr.load_state_dict(state_dict)\n",
    "\n",
    "# Test that state was restored correctly\n",
    "batch_original = replay_mgr.buffer.sample()\n",
    "batch_restored = new_replay_mgr.buffer.sample()\n",
    "\n",
    "print(\"State restoration test:\")\n",
    "print(\n",
    "    f\"  Original indices: {batch_original.get('index', torch.zeros(batch_original.batch_size[0])).tolist()}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Restored indices: {batch_restored.get('index', torch.zeros(batch_restored.batch_size[0])).tolist()}\"\n",
    ")\n",
    "\n",
    "# Clean up\n",
    "del new_manager, new_replay_mgr\n",
    "\n",
    "print(\"✅ State persistence test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test 9: Multi-Task and Multi-Trajectory Simulation\n",
    "\n",
    "print(\"Testing multi-task and multi-trajectory scenarios...\")\n",
    "\n",
    "# Create synthetic multi-task scenario\n",
    "from iltools_datasets.replay_manager import ExpertReplayManager, ExpertReplaySpec\n",
    "from iltools_datasets.replay_memmap import build_trajectory_td\n",
    "\n",
    "\n",
    "def create_multi_task_scenario():\n",
    "    \"\"\"Create a scenario with multiple tasks and trajectories.\"\"\"\n",
    "    tasks = {}\n",
    "\n",
    "    # Task 0: Multiple trajectories of different lengths\n",
    "    tasks[0] = [\n",
    "        _mk_traj(0, 0, T=10, obs_dim=4, act_dim=2),  # Short trajectory\n",
    "        _mk_traj(0, 1, T=15, obs_dim=4, act_dim=2),  # Medium trajectory\n",
    "        _mk_traj(0, 2, T=5, obs_dim=4, act_dim=2),  # Very short trajectory\n",
    "    ]\n",
    "\n",
    "    # Task 1: Single long trajectory\n",
    "    tasks[1] = [\n",
    "        _mk_traj(1, 0, T=20, obs_dim=4, act_dim=2),\n",
    "    ]\n",
    "\n",
    "    # Task 2: Multiple short trajectories\n",
    "    tasks[2] = [\n",
    "        _mk_traj(2, 0, T=8, obs_dim=4, act_dim=2),\n",
    "        _mk_traj(2, 1, T=12, obs_dim=4, act_dim=2),\n",
    "    ]\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "# Create multi-task replay manager\n",
    "multi_tasks = create_multi_task_scenario()\n",
    "tmp_dir_multi = str((Path.cwd() / \"_tmp_multi_task\").absolute())\n",
    "multi_mgr = ExpertReplayManager(\n",
    "    ExpertReplaySpec(\n",
    "        tasks=multi_tasks, scratch_dir=tmp_dir_multi, device=\"cpu\", sample_batch_size=6\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Multi-task scenario created:\")\n",
    "for task_id, trajs in multi_tasks.items():\n",
    "    print(\n",
    "        f\"  Task {task_id}: {len(trajs)} trajectories with lengths {[t.shape[0] for t in trajs]}\"\n",
    "    )\n",
    "\n",
    "# Test assignment across different tasks\n",
    "print(\"\\nTesting cross-task assignments:\")\n",
    "cross_task_assignment = [\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=0),  # Task 0, Traj 0\n",
    "    EnvAssignment(task_id=0, traj_id=1, step=0),  # Task 0, Traj 1\n",
    "    EnvAssignment(task_id=1, traj_id=0, step=0),  # Task 1, Traj 0\n",
    "    EnvAssignment(task_id=2, traj_id=0, step=0),  # Task 2, Traj 0\n",
    "    EnvAssignment(task_id=2, traj_id=1, step=0),  # Task 2, Traj 1\n",
    "    EnvAssignment(task_id=0, traj_id=2, step=0),  # Task 0, Traj 2\n",
    "]\n",
    "\n",
    "multi_mgr.set_assignment(cross_task_assignment)\n",
    "\n",
    "# Sample and verify different trajectories\n",
    "for i in range(3):\n",
    "    batch = multi_mgr.buffer.sample()\n",
    "    obs = batch[\"observation\"]\n",
    "    print(f\"Step {i}:\")\n",
    "    for j in range(len(cross_task_assignment)):\n",
    "        task_id = cross_task_assignment[j].task_id\n",
    "        traj_id = cross_task_assignment[j].traj_id\n",
    "        print(\n",
    "            f\"  Env {j} (Task {task_id}, Traj {traj_id}): obs[0]={obs[j, 0].item():.1f}\"\n",
    "        )\n",
    "\n",
    "# Test wraparound across different trajectory lengths\n",
    "print(\"\\nTesting wraparound with different trajectory lengths:\")\n",
    "# Set assignments near the end of different trajectories\n",
    "wraparound_assignment = [\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=8),  # Near end of T=10 traj\n",
    "    EnvAssignment(task_id=0, traj_id=1, step=12),  # Near end of T=15 traj\n",
    "    EnvAssignment(task_id=1, traj_id=0, step=18),  # Near end of T=20 traj\n",
    "]\n",
    "\n",
    "multi_mgr.set_assignment(wraparound_assignment)\n",
    "\n",
    "for i in range(5):\n",
    "    batch = multi_mgr.buffer.sample()\n",
    "    indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "    print(f\"Wraparound step {i}: indices {indices.tolist()}\")\n",
    "\n",
    "print(\"✅ Multi-task simulation test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e991bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test 10: Comprehensive Integration Test\n",
    "\n",
    "print(\"Running comprehensive integration test...\")\n",
    "\n",
    "# Reset to original replay manager for final integration test\n",
    "replay_mgr.set_assignment(\n",
    "    [EnvAssignment(task_id=0, traj_id=0, step=0) for _ in range(4)]\n",
    ")\n",
    "\n",
    "# Test complete workflow: sequential -> uniform -> sequential with state changes\n",
    "print(\"Testing complete workflow:\")\n",
    "\n",
    "# Phase 1: Sequential sampling with progression\n",
    "print(\"Phase 1: Sequential sampling\")\n",
    "sequential_states = []\n",
    "for i in range(5):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "    sequential_states.append(indices.clone())\n",
    "    print(f\"  Step {i}: {indices.tolist()}\")\n",
    "\n",
    "# Phase 2: Switch to uniform sampling\n",
    "print(\"\\nPhase 2: Uniform sampling\")\n",
    "replay_mgr.set_uniform_sampler(batch_size=8, without_replacement=True)\n",
    "uniform_samples = []\n",
    "for i in range(3):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "    uniform_samples.append(indices.clone())\n",
    "    print(f\"  Sample {i}: {indices.tolist()}\")\n",
    "\n",
    "# Phase 3: Switch back to sequential with new assignment\n",
    "print(\"\\nPhase 3: Sequential with new assignment\")\n",
    "new_assignment = [\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=1000),\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=2000),\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=500),\n",
    "    EnvAssignment(task_id=0, traj_id=0, step=0),\n",
    "]\n",
    "replay_mgr.set_assignment(new_assignment)\n",
    "\n",
    "sequential_after_uniform = []\n",
    "for i in range(3):\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    indices = batch.get(\"index\", torch.zeros(batch.batch_size[0]))\n",
    "    sequential_after_uniform.append(indices.clone())\n",
    "    print(f\"  Step {i}: {indices.tolist()}\")\n",
    "\n",
    "# Phase 4: Test data consistency\n",
    "print(\"\\nPhase 4: Data consistency validation\")\n",
    "batch = replay_mgr.buffer.sample()\n",
    "obs = batch[\"observation\"]\n",
    "next_obs = batch[\"next\"][\"observation\"]\n",
    "actions = batch[\"action\"]\n",
    "\n",
    "# Verify data properties\n",
    "assert obs.shape[0] == 4, f\"Expected batch size 4, got {obs.shape[0]}\"\n",
    "assert obs.shape[1] == 30, f\"Expected obs dim 30, got {obs.shape[1]}\"\n",
    "assert actions.shape == (4, 1), f\"Expected action shape (4,1), got {actions.shape}\"\n",
    "assert (\n",
    "    obs.device == next_obs.device\n",
    "), \"Observation and next observation should be on same device\"\n",
    "\n",
    "# Verify no NaN or Inf values\n",
    "assert not torch.isnan(obs).any(), \"Observations contain NaN values\"\n",
    "assert not torch.isinf(obs).any(), \"Observations contain Inf values\"\n",
    "assert not torch.isnan(actions).any(), \"Actions contain NaN values\"\n",
    "\n",
    "print(\"✅ All data consistency checks passed\")\n",
    "\n",
    "# Phase 5: Performance summary\n",
    "print(\"\\nPhase 5: Performance summary\")\n",
    "total_transitions = len(replay_mgr.buffer)\n",
    "num_segments = len(replay_mgr.segments)\n",
    "print(f\"  Total transitions: {total_transitions:,}\")\n",
    "print(f\"  Number of segments: {num_segments}\")\n",
    "print(f\"  Average segment length: {total_transitions // num_segments:,}\")\n",
    "\n",
    "# Test memory efficiency\n",
    "batch_sizes = [64, 128, 256, 512, 1024]\n",
    "for bs in batch_sizes:\n",
    "    replay_mgr.set_uniform_sampler(batch_size=bs, without_replacement=True)\n",
    "    start_time = time.time()\n",
    "    batch = replay_mgr.buffer.sample()\n",
    "    end_time = time.time()\n",
    "    print(f\"  Batch size {bs:4d}: {(end_time-start_time)*1000:6.2f} ms\")\n",
    "\n",
    "print(\"\\n🎉 Comprehensive integration test completed successfully!\")\n",
    "print(\"All replay buffer functionality is working correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a57dbe",
   "metadata": {},
   "source": [
    "## Test Summary\n",
    "\n",
    "The comprehensive tests added to this notebook cover:\n",
    "\n",
    "### Core Functionality Tests\n",
    "1. **Multiple Trajectory Loading** - Tests loading and managing multiple trajectories from different sources\n",
    "2. **Dynamic Assignment Updates** - Tests reassigning environments to different trajectories and starting positions\n",
    "3. **Wraparound and Boundary Testing** - Tests behavior at trajectory boundaries and wraparound logic\n",
    "4. **Sampler Switching** - Tests switching between sequential and uniform samplers\n",
    "5. **Data Integrity** - Tests tensor properties, device consistency, and data validity\n",
    "\n",
    "### Advanced Feature Tests\n",
    "6. **Performance and Memory Usage** - Tests sampling performance and memory efficiency\n",
    "7. **Error Handling** - Tests edge cases and error conditions\n",
    "8. **State Persistence** - Tests saving and restoring replay buffer state\n",
    "9. **Multi-Task Simulation** - Tests complex scenarios with multiple tasks and trajectories\n",
    "10. **Integration Test** - Comprehensive end-to-end workflow validation\n",
    "\n",
    "### Key Features Validated\n",
    "- ✅ Sequential per-environment sampling with wraparound\n",
    "- ✅ Uniform random sampling with/without replacement\n",
    "- ✅ Dynamic trajectory assignment updates\n",
    "- ✅ Cross-task and cross-trajectory assignments\n",
    "- ✅ Device management and tensor consistency\n",
    "- ✅ State serialization and recovery\n",
    "- ✅ Error handling and edge cases\n",
    "- ✅ Performance optimization and memory efficiency\n",
    "\n",
    "These tests ensure the replay buffer system is robust, efficient, and suitable for imitation learning applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SkillLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
