{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f269085a",
   "metadata": {},
   "source": [
    "# Export ReplayBuffer from LoCo-MuJoCo (UnitreeG1, default:walking)\n",
    "\n",
    "- Loads Unitree G1 in LoCo-MuJoCo and selects the 'walking' motion from the default dataset (alias: 'walk').\n",
    "- Uses `TrajectoryDatasetManager` to create Zarr if missing and to step reference data.\n",
    "- Builds a TorchRL memmap-backed replay buffer from the saved Zarr.\n",
    "- Demonstrates step-wise sequential sampling and random minibatch sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b0d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os, gc, json, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from tensordict import TensorDict\n",
    "\n",
    "# Repo import for local package\n",
    "repo_root = Path.cwd().parent\n",
    "if (repo_root / \"src\").exists():\n",
    "    sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "from iltools_datasets.loco_mujoco.loader import LocoMuJoCoLoader\n",
    "from iltools_datasets.manager import TrajectoryDatasetManager\n",
    "from iltools_datasets.replay_export import build_replay_from_zarr\n",
    "from iltools_datasets.replay_manager import EnvAssignment\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47ccd54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fad519",
   "metadata": {},
   "source": [
    "## Configure LoCo-MuJoCo (G1 walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3850f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LocoMuJoCoLoader] Initializing LocoMuJoCoLoader\n",
      "[LocoMuJoCoLoader] Dataset dictionary: {'default': ['walk'], 'amass': [], 'lafan1': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35198/35198 [00:05<00:00, 6815.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 joints\n",
      "joint_names ['root', 'left_hip_pitch_joint', 'left_hip_roll_joint', 'left_hip_yaw_joint', 'left_knee_joint', 'left_ankle_pitch_joint', 'left_ankle_roll_joint', 'right_hip_pitch_joint', 'right_hip_roll_joint', 'right_hip_yaw_joint', 'right_knee_joint', 'right_ankle_pitch_joint', 'right_ankle_roll_joint', 'waist_yaw_joint', 'left_shoulder_pitch_joint', 'left_shoulder_roll_joint', 'left_shoulder_yaw_joint', 'left_elbow_joint', 'left_wrist_roll_joint', 'right_shoulder_pitch_joint', 'right_shoulder_roll_joint', 'right_shoulder_yaw_joint', 'right_elbow_joint', 'right_wrist_roll_joint']\n"
     ]
    }
   ],
   "source": [
    "# LoCo-MuJoCo base cfg (see tests for example usage)\n",
    "basic_cfg = DictConfig(\n",
    "    {\n",
    "        \"dataset\": {\"trajectories\": {\"default\": [\"walk\"], \"amass\": [], \"lafan1\": []}},\n",
    "        \"control_freq\": 50.0,\n",
    "        \"window_size\": 4,\n",
    "        \"sim\": {\"dt\": 0.001},\n",
    "        \"decimation\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Resolve joint names via loader metadata to satisfy manager mapping\n",
    "tmp_loader = LocoMuJoCoLoader(env_name=\"UnitreeG1\", cfg=basic_cfg)\n",
    "joint_names = list(tmp_loader.metadata.joint_names)\n",
    "print(\"Found\", len(joint_names), \"joints\")\n",
    "print(\"joint_names\", joint_names)\n",
    "del tmp_loader\n",
    "joint_names = joint_names[1:]  # no need for root joint\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(repo_root) / \"examples\" / \"data\" / \"g1_default_walk\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ZARR_PATH = DATA_DIR / \"trajectories.zarr\"\n",
    "\n",
    "# Manager cfg (creates Zarr if missing using LocoMuJoCoLoader)\n",
    "mgr_cfg = DictConfig(\n",
    "    {\n",
    "        \"dataset_path\": str(DATA_DIR),\n",
    "        \"dataset\": {\"trajectories\": {\"default\": [\"walk\"], \"amass\": [], \"lafan1\": []}},\n",
    "        \"loader_type\": \"loco_mujoco\",\n",
    "        \"loader_kwargs\": {\"env_name\": \"UnitreeG1\", \"cfg\": basic_cfg},\n",
    "        \"assignment_strategy\": \"sequential\",\n",
    "        \"window_size\": 4,\n",
    "        \"target_joint_names\": joint_names,\n",
    "        \"reference_joint_names\": joint_names,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea43bc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TrajectoryDatasetManager] Using device: cuda:0\n",
      "[TrajectoryDatasetManager] Initialized with 1 trajectories, 8 envs\n",
      "Reference data keys: ['root_pos', 'root_quat', 'root_lin_vel', 'root_ang_vel', 'joint_pos', 'joint_vel', 'raw_qpos', 'raw_qvel']\n",
      "Zarr ready at: /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/trajectories.zarr\n"
     ]
    }
   ],
   "source": [
    "manager = TrajectoryDatasetManager(cfg=mgr_cfg, num_envs=8, device=\"cuda:0\")\n",
    "manager.reset_trajectories()\n",
    "ref0 = manager.get_reference_data()\n",
    "print(\"Reference data keys:\", list(ref0.keys()))\n",
    "print(\"Zarr ready at:\", ZARR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46cc3c",
   "metadata": {},
   "source": [
    "## Build memmap-backed replay buffer from Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ebb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[build_replay_from_zarr] td: TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([87994, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                observation: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                qpos: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([87994]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        qpos: Tensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([87994]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/memmap with range 0 to 87994\n",
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/memmap with range 0 to 87994\n",
      "Replay transitions available: 87994\n"
     ]
    }
   ],
   "source": [
    "# Export replay using qpos as observation; action auto-detected if present\n",
    "replay_mgr = build_replay_from_zarr(\n",
    "    zarr_path=str(ZARR_PATH),\n",
    "    scratch_dir=str(DATA_DIR / \"memmap\"),\n",
    "    obs_keys=[\"qpos\"],\n",
    "    concat_obs_to_key=\"observation\",\n",
    "    include_terminated=True,\n",
    "    include_truncated=True,\n",
    ")\n",
    "print(\"Replay transitions available:\", len(replay_mgr.buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9026e928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDictReplayBuffer(\n",
       "    storage=LazyMemmapStorage(\n",
       "        data=TensorDict(\n",
       "            fields={\n",
       "                action: MemoryMappedTensor(shape=torch.Size([87994, 1]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                next: TensorDict(\n",
       "                    fields={\n",
       "                        observation: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                        qpos: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True)},\n",
       "                    batch_size=torch.Size([87994]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                observation: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                qpos: MemoryMappedTensor(shape=torch.Size([87994, 30]), device=cpu, dtype=torch.float32, is_shared=True),\n",
       "                terminated: MemoryMappedTensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=True),\n",
       "                truncated: MemoryMappedTensor(shape=torch.Size([87994]), device=cpu, dtype=torch.bool, is_shared=True)},\n",
       "            batch_size=torch.Size([87994]),\n",
       "            device=cpu,\n",
       "            is_shared=False), \n",
       "        shape=torch.Size([87994]), \n",
       "        len=87994, \n",
       "        max_size=87994), \n",
       "    sampler=RandomSampler(), \n",
       "    writer=TensorDictRoundRobinWriter(cursor=0, full_storage=True), \n",
       "    batch_size=256, \n",
       "    collate_fn=<function _collate_id at 0x7f2ec81c74c0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = replay_mgr.buffer\n",
    "buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b99ce3",
   "metadata": {},
   "source": [
    "## Step-wise sequential sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcc242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential batch1 shape: {'observation': (8, 30), 'action': (8, 1), 'qpos': (8, 30), 'terminated': (8,), 'truncated': (8,), 'index': (8,)}\n",
      "Sequential batch2 observation head: tensor([[ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
      "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
      "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
      "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
      "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
      "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
      "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
      "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
      "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
      "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
      "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
      "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Build a simple assignment: all 8 envs read the first segment (task 0, traj 0)\n",
    "asg = [EnvAssignment(task_id=0, traj_id=0, step=0) for i in range(8)]\n",
    "replay_mgr.set_assignment(asg)\n",
    "# Sample twice; each env advances one step and wraps per-trajectory\n",
    "b1 = replay_mgr.buffer.sample()\n",
    "b2 = replay_mgr.buffer.sample()\n",
    "print(\n",
    "    \"Sequential batch1 shape:\",\n",
    "    {k: tuple(v.shape) for k, v in b1.items() if isinstance(v, torch.Tensor)},\n",
    ")\n",
    "print(\"Sequential batch2 observation head:\", b2[\"observation\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664],\n",
       "        [ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664],\n",
       "        [ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664],\n",
       "        [ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664],\n",
       "        [ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664],\n",
       "        [ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664],\n",
       "        [ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664],\n",
       "        [ 0.0000,  0.0000,  0.7905,  0.9951,  0.0016,  0.0764,  0.0624,  0.1464,\n",
       "         -0.0225, -0.0381,  0.2012, -0.3344,  0.0427, -0.6798, -0.0301, -0.1662,\n",
       "          0.1969, -0.0031, -0.0641, -0.1703, -0.2879,  0.1746,  0.1106,  0.5922,\n",
       "          0.0746,  0.2183, -0.0113, -0.9256,  1.3148, -1.2664]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1[\"observation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba38e9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00],\n",
       "        [ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01,  2.6733e-03,\n",
       "          7.5421e-02,  6.3350e-02,  1.5073e-01, -2.4139e-02, -4.5167e-02,\n",
       "          2.1360e-01, -3.2380e-01,  4.2471e-02, -6.7555e-01, -2.7696e-02,\n",
       "         -1.5894e-01,  2.0293e-01,  9.8581e-03, -6.1347e-02, -1.7089e-01,\n",
       "         -2.8424e-01,  1.7141e-01,  1.1185e-01,  5.9139e-01,  7.3095e-02,\n",
       "          2.1847e-01, -1.1540e-02, -9.2835e-01,  1.3153e+00, -1.2692e+00]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2[\"observation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12992d04",
   "metadata": {},
   "source": [
    "## Random minibatch sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d82de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random minibatch size: torch.Size([1024])\n",
      "Keys: ['observation', 'action', ('next', 'observation'), ('next', 'qpos'), 'next', 'qpos', 'terminated', 'truncated', 'index']\n"
     ]
    }
   ],
   "source": [
    "# Switch to uniform random minibatch sampler (without replacement)\n",
    "replay_mgr.set_uniform_sampler(batch_size=1024, without_replacement=True)\n",
    "rb_batch = replay_mgr.buffer.sample()\n",
    "print(\"Random minibatch size:\", rb_batch.batch_size)\n",
    "print(\"Keys:\", list(rb_batch.keys(True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e0d01",
   "metadata": {},
   "source": [
    "## Replay Buffer Examples and Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a579d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num segments: 1\n",
      "First 3 segments: [(0, 0, 87994)]\n",
      "Sampled keys: ['observation', 'action', ('next', 'observation'), ('next', 'qpos'), 'next', 'qpos', 'terminated', 'truncated', 'index']\n",
      "Has terminated? True Has truncated? True\n",
      "Batch sizes: {'observation': (1024, 30), 'action': (1024, 1), 'next': (1024,), 'qpos': (1024, 30), 'terminated': (1024,), 'truncated': (1024,), 'index': (1024,)}\n"
     ]
    }
   ],
   "source": [
    "# Inspect segment metadata and presence of auxiliary keys\n",
    "print(\"Num segments:\", len(replay_mgr.segments))\n",
    "print(\n",
    "    \"First 3 segments:\",\n",
    "    [(s.task_id, s.traj_id, s.length) for s in replay_mgr.segments[:3]],\n",
    ")\n",
    "batch = replay_mgr.buffer.sample()\n",
    "print(\"Sampled keys:\", list(batch.keys(True)))\n",
    "print(\"Has terminated?\", \"terminated\" in batch, \"Has truncated?\", \"truncated\" in batch)\n",
    "print(\n",
    "    \"Batch sizes:\", {k: tuple(v.shape) for k, v in batch.items() if hasattr(v, \"shape\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba57f35",
   "metadata": {},
   "source": [
    "### Step-wise Sequential Sampler (assignment and wraparound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86026f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential sampler shapes: torch.Size([6, 30]) torch.Size([6, 30])\n",
      "First env obs head b1/b2: tensor([0.0000, 0.0000, 0.7905, 0.9951]) tensor([ 8.9815e-03, -6.0037e-04,  7.8958e-01,  9.9513e-01])\n"
     ]
    }
   ],
   "source": [
    "# Assign all envs to the first segment and stagger start steps to show progression\n",
    "first_seg = replay_mgr.segments[0]\n",
    "num_envs = 6\n",
    "asg = [\n",
    "    EnvAssignment(task_id=first_seg.task_id, traj_id=first_seg.traj_id, step=i)\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "replay_mgr.set_assignment(asg)\n",
    "b1 = replay_mgr.buffer.sample()\n",
    "b2 = replay_mgr.buffer.sample()\n",
    "print(\"Sequential sampler shapes:\", b1[\"observation\"].shape, b2[\"observation\"].shape)\n",
    "print(\"First env obs head b1/b2:\", b1[\"observation\"][0, :4], b2[\"observation\"][0, :4])\n",
    "# Note: Actual values depend on dataset; we demonstrate API and per-call advancement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f66b9d",
   "metadata": {},
   "source": [
    "### Random Minibatch Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e06d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform minibatch size: torch.Size([512])\n",
      "With-replacement minibatch size: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Switch to uniform minibatching (without replacement)\n",
    "replay_mgr.set_uniform_sampler(batch_size=512, without_replacement=True)\n",
    "rb_batch = replay_mgr.buffer.sample()\n",
    "print(\"Uniform minibatch size:\", rb_batch.batch_size)\n",
    "# With replacement (sampler=None)\n",
    "replay_mgr.set_uniform_sampler(batch_size=128, without_replacement=False)\n",
    "rb_batch_rep = replay_mgr.buffer.sample()\n",
    "print(\"With-replacement minibatch size:\", rb_batch_rep.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b85ed",
   "metadata": {},
   "source": [
    "### Device Transform (prefetch to GPU if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e21b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n",
      "Device: cpu\n",
      "Device types match: False\n",
      "❌ Device transform failed - data still on CPU\n",
      "This might be due to buffer recreation losing transforms. Check replay_manager.py\n"
     ]
    }
   ],
   "source": [
    "# Force reload of the replay_manager module to pick up latest changes\n",
    "import importlib\n",
    "import iltools_datasets.replay_manager\n",
    "\n",
    "importlib.reload(iltools_datasets.replay_manager)\n",
    "\n",
    "target_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device:\", target_device)\n",
    "replay_mgr.set_device_transform(target_device)\n",
    "bs = replay_mgr.buffer.sample()\n",
    "print(\"Device:\", bs[\"observation\"].device)\n",
    "print(\"Device types match:\", bs[\"observation\"].device.type == target_device.type)\n",
    "if bs[\"observation\"].device.type == target_device.type:\n",
    "    print(\"✅ Device transform ok\")\n",
    "else:\n",
    "    print(\"❌ Device transform failed - data still on CPU\")\n",
    "    print(\n",
    "        \"This might be due to buffer recreation losing transforms. Check replay_manager.py\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a44b7",
   "metadata": {},
   "source": [
    "### Synthetic Tests (deterministic observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/_tmp_memmap with range 0 to 3\n",
      "[ExpertMemmapBuilder] setting storage in dir /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/_tmp_memmap with range 3 to 5\n",
      "✅ Sequential sampler synthetic test passed\n",
      "✅ Uniform sampler tests passed\n"
     ]
    }
   ],
   "source": [
    "from iltools_datasets.replay_manager import ExpertReplayManager, ExpertReplaySpec\n",
    "from iltools_datasets.replay_memmap import build_trajectory_td, Segment\n",
    "\n",
    "\n",
    "def _mk_traj(task_id: int, traj_id: int, T: int, obs_dim: int = 3, act_dim: int = 1):\n",
    "    t = torch.arange(T, dtype=torch.float32).unsqueeze(-1)\n",
    "    obs = torch.cat(\n",
    "        [torch.full_like(t, float(task_id)), torch.full_like(t, float(traj_id)), t],\n",
    "        dim=1,\n",
    "    )\n",
    "    nxt = obs + 0.5\n",
    "    act = torch.zeros(T, act_dim)\n",
    "    return build_trajectory_td(observation=obs, action=act, next_observation=nxt)\n",
    "\n",
    "\n",
    "# Build small tasks set\n",
    "tasks = {0: [_mk_traj(0, 0, T=3)], 1: [_mk_traj(1, 0, T=2)]}\n",
    "tmp_dir = str((Path.cwd() / \"_tmp_memmap\").absolute())\n",
    "mgr2 = ExpertReplayManager(\n",
    "    ExpertReplaySpec(\n",
    "        tasks=tasks, scratch_dir=tmp_dir, device=\"cpu\", sample_batch_size=4\n",
    "    )\n",
    ")\n",
    "\n",
    "# Sequential assignment for 3 envs\n",
    "asg = [EnvAssignment(0, 0, 0), EnvAssignment(1, 0, 0), EnvAssignment(0, 0, 2)]\n",
    "mgr2.set_assignment(asg)\n",
    "out = mgr2.buffer.sample()\n",
    "obs = out[\"observation\"]\n",
    "assert torch.allclose(obs[0], torch.tensor([0.0, 0.0, 0.0]))\n",
    "assert torch.allclose(obs[1], torch.tensor([1.0, 0.0, 0.0]))\n",
    "assert torch.allclose(obs[2], torch.tensor([0.0, 0.0, 2.0]))\n",
    "out2 = mgr2.buffer.sample()\n",
    "obs2 = out2[\"observation\"]\n",
    "assert torch.allclose(obs2[0], torch.tensor([0.0, 0.0, 1.0]))\n",
    "assert torch.allclose(obs2[1], torch.tensor([1.0, 0.0, 1.0]))\n",
    "assert torch.allclose(obs2[2], torch.tensor([0.0, 0.0, 0.0]))\n",
    "print(\"✅ Sequential sampler synthetic test passed\")\n",
    "\n",
    "# Uniform samplers\n",
    "mgr2.set_uniform_sampler(batch_size=5, without_replacement=True)\n",
    "u1 = mgr2.buffer.sample()\n",
    "assert u1.batch_size[0] == 5\n",
    "mgr2.set_uniform_sampler(batch_size=3, without_replacement=False)\n",
    "u2 = mgr2.buffer.sample()\n",
    "assert u2.batch_size[0] == 3\n",
    "print(\"✅ Uniform sampler tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc693307",
   "metadata": {},
   "source": [
    "### Zarr Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ea2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zarr: /home/fwu/Documents/Research/SkillLearning/ImitationLearningTools/examples/data/g1_default_walk/trajectories.zarr\n",
      "- Dataset source: loco_mujoco (motions: 1)\n",
      "  • Motion:         default_walk | trajs:   1 | mean T: 87995.0 | total T: 87995\n"
     ]
    }
   ],
   "source": [
    "import zarr, os\n",
    "\n",
    "if \"ZARR_PATH\" not in globals():\n",
    "    print(\"ZARR_PATH is undefined. Run the configuration cells first.\")\n",
    "else:\n",
    "    zp = str(ZARR_PATH)\n",
    "    if not os.path.exists(zp):\n",
    "        print(\"Zarr not found at\", zp, \"- run earlier cells to create it.\")\n",
    "    else:\n",
    "        root = zarr.open_group(zp, mode=\"r\")\n",
    "        print(\"Zarr:\", zp)\n",
    "        for ds_name in root.keys():\n",
    "            ds_group = root[ds_name]\n",
    "            motions = [\n",
    "                k for k in ds_group.keys() if isinstance(ds_group[k], zarr.Group)\n",
    "            ]\n",
    "            print(f\"- Dataset source: {ds_name} (motions: {len(motions)})\")\n",
    "            for motion in motions:\n",
    "                mg = ds_group[motion]\n",
    "                trajs = [k for k in mg.keys() if isinstance(mg[k], zarr.Group)]\n",
    "                lengths = []\n",
    "                for traj in trajs:\n",
    "                    tg = mg[traj]\n",
    "                    # Prefer 'qpos' to determine T, else first array key\n",
    "                    arr_key = (\n",
    "                        \"qpos\"\n",
    "                        if \"qpos\" in tg\n",
    "                        else next(\n",
    "                            (k for k in tg.keys() if isinstance(tg[k], zarr.Array)),\n",
    "                            None,\n",
    "                        )\n",
    "                    )\n",
    "                    T = int(tg[arr_key].shape[0]) if arr_key is not None else -1\n",
    "                    lengths.append(T)\n",
    "                total_T = sum(max(0, T) for T in lengths)\n",
    "                print(\n",
    "                    f\"  • Motion: {motion:>20} | trajs: {len(trajs):3d} | mean T: { (sum(lengths)/len(lengths)) if lengths else 0:.1f} | total T: {total_T}\"\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SkillLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
